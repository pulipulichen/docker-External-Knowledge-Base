version: '3.8'

services:
  api:
    build: .
    expose:
      - "80"
    ports:
      - "8081:80"
    volumes:
      - .:/app
    env_file:
      - .env

  nginx:
    image: nginx:1.21.6
    ports:
      - "8080:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api

  tei_bge_m3:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.6
    environment:
      - MODEL_ID=BAAI/bge-m3
      # ...
    restart: on-failure
    volumes:
      - tei_bge_m3:/data
    cap_add:
      - SYS_ADMIN
    security_opt:
      - seccomp=unconfined

volumes:
  tei_bge_m3:
