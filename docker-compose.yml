version: '3.8'

services:
  api:
    build: .
    expose:
      - "80"
    volumes:
      - .:/app
    env_file:
      - .env
    depends_on:
      - redis

  redis:
    image: "redis:7.0.12-alpine"
    volumes:
      - redis_data:/data

  nginx:
    image: nginx:1.21.6
    ports:
      - "8080:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api

  tei_bge_m3:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.6
    environment:
      - MODEL_ID=BAAI/bge-m3
      # ...
    restart: on-failure
    volumes:
      - tei_bge_m3:/data
    cap_add:
      - SYS_ADMIN
    security_opt:
      - seccomp=unconfined
    logging:
      driver: "none"
  weaviate:
    image: semitechnologies/weaviate:1.31.6-bb985f0.amd64
    # restart: on-failure
    # ports: # 暴露 Weaviate 服務的端口到主機
    #   - "58080:8080" # 將容器的 8080 端口映射到主機的 58080 端口 (HTTP)
    #   - "50051:50051" # 將容器的 50051 端口映射到主機的 50051 端口 (gRPC)
    environment:
      QUERY_DEFAULTS_LIMIT: 100
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      # DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'
      CLUSTER_HOSTNAME: 'node1'
      # ENABLE_MODULES: 'text2vec-openai'
      # CLUSTER_HOST: '' # Add this line
      # CLUSTER_ENABLED: 'false'
      # LIMIT_RESOURCES: true
      # RAFT_BOOTSTRAP_EXPECT: '1'
    volumes:
      - weaviate_data:/var/lib/weaviate
      # - ./weaviate/entrypoint.sh:/entrypoint.sh
    env_file:
      - .env
    logging:
      driver: "none"
    # entrypoint: []
    # command: ["/entrypoint.sh"]
  weaviate_ui:
    image: naaive/weaviate-ui:v1.0.3
    # restart: on-failure
    ports:
      - 47777:7777
    depends_on:
      - weaviate
    environment:
      - WEAVIATE_URL=http://weaviate:8080
    env_file:
      - .env
    # networks:
    #   - document_semantic_database


volumes:
  tei_bge_m3:
  redis_data:
  weaviate_data:
